import librosa
import numpy as np
import sounddevice as sd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from matplotlib.animation import FuncAnimation
import time

frame_data_list = []

# === 1. Load audio ===
y, sr = librosa.load("song.mp3", sr=None, mono=True)
total_seconds = len(y) / sr

# === 2. Compute frame-level audio features ===
hop_length = 1024
frame_length = 2048

# RMS (energy/arousal)
rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]
rms_norm = (rms - rms.min()) / (rms.max() - rms.min())

# Spectral centroid (brightness/valence)
spec_centroid = librosa.feature.spectral_centroid(y=y, sr=sr, hop_length=hop_length)[0]
centroid_norm = (spec_centroid - spec_centroid.min()) / (spec_centroid.max() - spec_centroid.min())

# RMS times for the amplitude graph
rms_times = np.linspace(0, total_seconds, len(rms))

# === 3. Map frames to emotion â†’ RGB ===
def emotion_to_color(loudness, brightness):
    """Map arousal (energy) and valence (brightness) to an RGB color."""
    happy = np.array([255, 223, 0])    # yellow
    sad = np.array([0, 51, 102])       # dark blue
    calm = np.array([128, 0, 128])     # purple
    angry = np.array([255, 77, 0])     # red-orange
    color = (
        brightness * (loudness * happy + (1 - loudness) * calm) +
        (1 - brightness) * (loudness * angry + (1 - loudness) * sad)
    )
    return np.clip(color / 255, 0, 1)

colors = np.array([emotion_to_color(a, v) for a, v in zip(rms_norm, centroid_norm)])

# === 4. Visualization setup ===
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 5), gridspec_kw={'height_ratios':[1,1]})
plt.subplots_adjust(hspace=0.35)

# --- Gradient subplot ---
ax1.axis("off")
gradient_length = 400
gradient_height = 50
gradient_data = np.zeros((gradient_height, gradient_length, 3))
im = ax1.imshow(gradient_data, aspect="auto")

time_text = fig.text(0.5, 0.95, "", ha="center", va="top", 
                     fontsize=12, fontweight="bold", color="black")

ax1.set_title("Emotional Colors of Music", fontsize=14, pad=10)

# --- RMS subplot ---
ax2.plot(rms_times, rms, color="cyan")
rms_playhead_line, = ax2.plot([0,0], [0, rms.max()], color="red", lw=1)
ax2.set_xlabel("Time (s)")
ax2.set_ylabel("Amplitude (RMS)")
ax2.set_title("Volume / Amplitude")
ax2.set_xlim(0, total_seconds)
ax2.set_ylim(0, rms.max()*1.05)

# === 5. Update function synced to audio ===
start_time = None
num_frames = len(rms_norm)

def update(frame):
    global gradient_data, start_time, frame_data_list
    if start_time is None:
        start_time = time.time()
    
    elapsed = time.time() - start_time
    elapsed = min(elapsed, total_seconds)
    if elapsed >= total_seconds:
        ani.event_source.stop()  # stop the animation
        elapsed = total_seconds
    
    # Map elapsed to current frame
    current_frame = int(elapsed / total_seconds * num_frames)
    current_frame = min(current_frame, num_frames - 1)
    
    # --- Update gradient with smooth emotional color ---
    new_color = colors[current_frame]
    prev_color = gradient_data[:, -1, :]
    blended = 0.8 * prev_color + 0.2 * new_color  # gradual blending
    gradient_data = np.roll(gradient_data, -1, axis=1)
    gradient_data[:, -1, :] = blended
    
    # Optional vertical fade for smoothness
    for i in range(gradient_height):
        gradient_data[i, -1, :] *= (0.7 + 0.3 * i / gradient_height)
    
    im.set_data(gradient_data)
    
    # --- Update timestamp ---
    current_min = int(elapsed // 60)
    current_sec = int(elapsed % 60)
    total_min = int(total_seconds // 60)
    total_sec = int(total_seconds % 60)
    time_text.set_text(f"{current_min:02d}:{current_sec:02d} / {total_min:02d}:{total_sec:02d}")
    
    # --- Update RMS playhead ---
    rms_playhead_line.set_data([elapsed, elapsed], [0, rms.max()*1.05])
    
    #Update frame data list
    #This is a list of lists, it goes [time_elapsed, R, G, B, RMS]
    frame_data_list.append([
        elapsed,
        float(colors[current_frame][0]),  # R
        float(colors[current_frame][1]),  # G
        float(colors[current_frame][2]),  # B
        float(rms[current_frame]),        # RMS
    ])
    return [im, time_text, rms_playhead_line]

# === 6. Play sound + animate ===
time.sleep(0.05)
sd.play(y, sr)
ani = FuncAnimation(fig, update, frames=num_frames, interval=30, blit=False)
plt.show()
sd.wait()
for i in range(min(10, len(frame_data_list))):
    print(frame_data_list[i])
