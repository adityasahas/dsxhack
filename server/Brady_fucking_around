import librosa
import numpy as np
import sounddevice as sd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from matplotlib.animation import FuncAnimation
import time

frame_data_list = []

# === 1. Load audio ===
y, sr = librosa.load("song0.mp3", sr=None, mono=True)
total_seconds = len(y) / sr

# === 2. Compute frame-level audio features ===
hop_length = 1024
frame_length = 2048

# RMS (energy/arousal)
rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]
rms_norm = (rms - rms.min()) / (rms.max() - rms.min())

# Spectral centroid (brightness/valence)
spec_centroid = librosa.feature.spectral_centroid(y=y, sr=sr, hop_length=hop_length)[0]
centroid_norm = (spec_centroid - spec_centroid.min()) / (spec_centroid.max() - spec_centroid.min())

# RMS times for the amplitude graph
rms_times = np.linspace(0, total_seconds, len(rms))

def brighten_color(color, factor):
    """Brighten an RGB color without washing out white."""
    brightened = color + (1 - color) * (factor - 1)
    return np.clip(brightened, 0, 1)

# === 3. Map frames to emotion â†’ RGB ===
def emotion_to_color(loudness, brightness):
    """Map arousal (energy) and valence (brightness) to an RGB color (vibrant)."""
    happy = np.array([255, 215, 0])     # slightly deeper gold
    sad   = np.array([0, 0, 100])       # darker blue
    calm  = np.array([0, 180, 120])     # teal but deeper
    angry = np.array([200, 0, 0])       # darker red

    color = (
        brightness * (loudness * happy + (1 - loudness) * calm) +
        (1 - brightness) * (loudness * angry + (1 - loudness) * sad)
    )
    color = np.clip(color / 255, 0, 1)
    color=brighten_color(color, factor=1.2)
    return color

colors_raw = np.array([emotion_to_color(a, v) for a, v in zip(rms_norm, centroid_norm)])

# --- Apply block_size for discrete sections ---
block_size = 30
num_frames = len(colors_raw)
colors = np.zeros_like(colors_raw)

for i in range(num_frames):
    block_index = i // block_size
    start_idx = block_index * block_size
    colors[i] = colors_raw[start_idx]

# === 4. Visualization setup ===
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 5), gridspec_kw={'height_ratios':[1,1]})
plt.subplots_adjust(hspace=0.35)

# --- Gradient subplot ---
ax1.axis("off")
gradient_length = 400
gradient_height = 50
gradient_data = np.zeros((gradient_height, gradient_length, 3))
im = ax1.imshow(gradient_data, aspect="auto")

time_text = fig.text(0.5, 0.95, "", ha="center", va="top", 
                     fontsize=12, fontweight="bold", color="black")

ax1.set_title("Emotional Colors of Music", fontsize=14, pad=10)

# --- RMS subplot ---
ax2.plot(rms_times, rms, color="cyan")
rms_playhead_line, = ax2.plot([0,0], [0, rms.max()], color="red", lw=1)
ax2.set_xlabel("Time (s)")
ax2.set_ylabel("Amplitude (RMS)")
ax2.set_title("Volume / Amplitude")
ax2.set_xlim(0, total_seconds)
ax2.set_ylim(0, rms.max()*1.05)

# === 5. Update function synced to audio ===
start_time = None
num_frames = len(rms_norm)

def update(frame):
    global gradient_data, start_time, frame_data_list
    if start_time is None:
        start_time = time.time()
    
    elapsed = time.time() - start_time
    elapsed = min(elapsed, total_seconds)
    if elapsed >= total_seconds:
        ani.event_source.stop()
        elapsed = total_seconds
    
    # --- Map elapsed time to audio frame ---
    current_frame = int(elapsed / total_seconds * num_frames)
    current_frame = min(current_frame, num_frames - 1)
    
    # --- Compute color ---
    new_color = colors[current_frame]

    # --- Shift gradient and add new bar ---
    gradient_data = np.roll(gradient_data, -1, axis=1)
    gradient_data[:, -1, :] = new_color

    # --- Mild smoothing between bars (keeps structure but softens edges) ---
    kernel = np.array([0.1, 0.15, 0.5, 0.15, 0.1])
    for c in range(3):
        gradient_data[:, :, c] = np.convolve(
            gradient_data[0, :, c], kernel, mode="same"
        )[None, :]  # apply along the x-axis only

    # --- Update image ---
    im.set_data(gradient_data)

    # --- Update timestamp text ---
    current_min = int(elapsed // 60)
    current_sec = int(elapsed % 60)
    total_min = int(total_seconds // 60)
    total_sec = int(total_seconds % 60)
    time_text.set_text(f"{current_min:02d}:{current_sec:02d} / {total_min:02d}:{total_sec:02d}")

    # --- Update RMS playhead line ---
    rms_playhead_line.set_data([elapsed, elapsed], [0, rms.max() * 1.05])

    # --- Record frame data ---
    frame_data_list.append([
        elapsed,
        float(new_color[0]),
        float(new_color[1]),
        float(new_color[2]),
        float(rms[current_frame]),
    ])

    return [im, time_text, rms_playhead_line]



# === 6. Play sound + animate ===
time.sleep(0.1)
sd.play(y, sr)
ani = FuncAnimation(fig, update, frames=num_frames, interval=30, blit=False)
plt.show()
sd.wait()
